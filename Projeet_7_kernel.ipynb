{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/Loryana/OCProjet7/blob/main/Projeet_7_kernel.ipynb",
      "authorship_tag": "ABX9TyOYxNqIZQc25mvhfAe6QWqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loryana/OCProjet7/blob/main/Projeet_7_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NHJYFYo3POpV",
        "outputId": "7835756a-477a-4e2d-ef25-1aeffd1cd454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "@contextmanager\n",
        "def timer(title):\n",
        "    t0 = time.time()\n",
        "    yield\n",
        "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n"
      ],
      "metadata": {
        "id": "TVn9wfkePxiI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding for categorical columns with get_dummies\n",
        "def one_hot_encoder(df, nan_as_category = True):\n",
        "    original_columns = list(df.columns)\n",
        "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
        "    new_columns = [c for c in df.columns if c not in original_columns]\n",
        "    return df, new_columns\n",
        "\n",
        "# Preprocess application_train.csv and application_test.csv\n",
        "def application_train_test(num_rows = None, nan_as_category = False):\n",
        "    # Read data and merge\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/application_train.csv', nrows= num_rows)\n",
        "    test_df = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/application_test.csv', nrows= num_rows)\n",
        "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
        "    df = pd.concat([df, test_df], ignore_index=True)\n",
        "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
        "    df = df[df['CODE_GENDER'] != 'XNA']\n",
        "\n",
        "    # Categorical features with Binary encode (0 or 1; two categories)\n",
        "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
        "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
        "    # Categorical features with One-Hot encode\n",
        "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
        "\n",
        "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
        "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
        "    # Some simple new features (percentages)\n",
        "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
        "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
        "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
        "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
        "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
        "    del test_df\n",
        "    gc.collect()\n",
        "    return df\n",
        "\n",
        "# Preprocess bureau.csv and bureau_balance.csv\n",
        "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
        "    bureau = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/bureau.csv', nrows = num_rows)\n",
        "    bb = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/bureau_balance.csv', nrows = num_rows)\n",
        "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
        "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
        "\n",
        "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
        "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
        "    for col in bb_cat:\n",
        "        bb_aggregations[col] = ['mean']\n",
        "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
        "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
        "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
        "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
        "    del bb, bb_agg\n",
        "    gc.collect()\n",
        "\n",
        "    # Bureau and bureau_balance numeric features\n",
        "    num_aggregations = {\n",
        "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
        "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
        "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
        "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
        "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
        "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
        "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
        "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
        "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
        "        'AMT_ANNUITY': ['max', 'mean'],\n",
        "        'CNT_CREDIT_PROLONG': ['sum'],\n",
        "        'MONTHS_BALANCE_MIN': ['min'],\n",
        "        'MONTHS_BALANCE_MAX': ['max'],\n",
        "        'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
        "    }\n",
        "    # Bureau and bureau_balance categorical features\n",
        "    cat_aggregations = {}\n",
        "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
        "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
        "\n",
        "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
        "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
        "    # Bureau: Active credits - using only numerical aggregations\n",
        "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
        "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
        "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
        "    del active, active_agg\n",
        "    gc.collect()\n",
        "    # Bureau: Closed credits - using only numerical aggregations\n",
        "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
        "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
        "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
        "    del closed, closed_agg, bureau\n",
        "    gc.collect()\n",
        "    return bureau_agg\n",
        "\n",
        "# Preprocess previous_applications.csv\n",
        "def previous_applications(num_rows = None, nan_as_category = True):\n",
        "    prev = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/previous_application.csv', nrows = num_rows)\n",
        "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
        "    # Days 365.243 values -> nan\n",
        "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "    # Add feature: value ask / value received percentage\n",
        "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
        "    # Previous applications numeric features\n",
        "    num_aggregations = {\n",
        "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
        "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
        "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
        "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
        "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
        "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
        "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "        'CNT_PAYMENT': ['mean', 'sum'],\n",
        "    }\n",
        "    # Previous applications categorical features\n",
        "    cat_aggregations = {}\n",
        "    for cat in cat_cols:\n",
        "        cat_aggregations[cat] = ['mean']\n",
        "\n",
        "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
        "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
        "    # Previous Applications: Approved Applications - only numerical features\n",
        "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
        "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
        "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
        "    # Previous Applications: Refused Applications - only numerical features\n",
        "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
        "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
        "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
        "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
        "    del refused, refused_agg, approved, approved_agg, prev\n",
        "    gc.collect()\n",
        "    return prev_agg\n",
        "\n",
        "# Preprocess POS_CASH_balance.csv\n",
        "def pos_cash(num_rows = None, nan_as_category = True):\n",
        "    pos = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/POS_CASH_balance.csv', nrows = num_rows)\n",
        "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
        "    # Features\n",
        "    aggregations = {\n",
        "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
        "        'SK_DPD': ['max', 'mean'],\n",
        "        'SK_DPD_DEF': ['max', 'mean']\n",
        "    }\n",
        "    for cat in cat_cols:\n",
        "        aggregations[cat] = ['mean']\n",
        "\n",
        "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
        "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
        "    # Count pos cash accounts\n",
        "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
        "    del pos\n",
        "    gc.collect()\n",
        "    return pos_agg\n",
        "\n",
        "# Preprocess installments_payments.csv\n",
        "def installments_payments(num_rows = None, nan_as_category = True):\n",
        "    ins = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/installments_payments.csv', nrows = num_rows)\n",
        "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
        "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
        "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
        "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
        "    # Days past due and days before due (no negative values)\n",
        "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
        "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
        "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
        "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
        "    # Features: Perform aggregations\n",
        "    aggregations = {\n",
        "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
        "        'DPD': ['max', 'mean', 'sum'],\n",
        "        'DBD': ['max', 'mean', 'sum'],\n",
        "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
        "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
        "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
        "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
        "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
        "    }\n",
        "    for cat in cat_cols:\n",
        "        aggregations[cat] = ['mean']\n",
        "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
        "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
        "    # Count installments accounts\n",
        "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
        "    del ins\n",
        "    gc.collect()\n",
        "    return ins_agg\n"
      ],
      "metadata": {
        "id": "VmOGzsqmPa4o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Preprocess credit_card_balance.csv\n",
        "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
        "    cc = pd.read_csv('/content/drive/MyDrive/Données OC/Projet 7/Données/credit_card_balance.csv', nrows = num_rows)\n",
        "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
        "    # General aggregations\n",
        "    cc.drop(columns = ['SK_ID_PREV'], inplace = True)\n",
        "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
        "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
        "    # Count credit card lines\n",
        "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
        "    labelencoder = LabelEncoder()\n",
        "    del cc\n",
        "\n",
        "    cat_feats = [\"CC_NAME_CONTRACT_STATUS_Active_MIN\", \"CC_NAME_CONTRACT_STATUS_Active_MAX\",\n",
        "                \"CC_NAME_CONTRACT_STATUS_Completed_MIN\", \"CC_NAME_CONTRACT_STATUS_Completed_MAX\",\n",
        "                 \"CC_NAME_CONTRACT_STATUS_Demand_MIN\", \"CC_NAME_CONTRACT_STATUS_Demand_MAX\",\n",
        "                  \"CC_NAME_CONTRACT_STATUS_Sent  proposal_MIN\", \"CC_NAME_CONTRACT_STATUS_Sent  proposal_MAX\",\n",
        "                 \"CC_NAME_CONTRACT_STATUS_Signed_MIN\", \"CC_NAME_CONTRACT_STATUS_Signed_MAX\", \"CC_NAME_CONTRACT_STATUS_nan_MIN\",\n",
        "                 \"CC_NAME_CONTRACT_STATUS_nan_MAX\"\n",
        "                 ]\n",
        "\n",
        "    for i in cat_feats:\n",
        "      cc_agg[i] = labelencoder.fit_transform(cc_agg[i])\n",
        "    for j in cat_feats:\n",
        "      cc_agg[j] = cc_agg[j].astype('int')\n",
        "\n",
        "    gc.collect()\n",
        "    return cc_agg"
      ],
      "metadata": {
        "id": "Nl7eJ4j-xvzC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display/plot feature importance\n",
        "def display_importances(feature_importance_df_):\n",
        "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
        "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
        "    plt.title('LightGBM Features (avg over folds)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('lgbm_importances01.png')"
      ],
      "metadata": {
        "id": "V_0YDNT_Pi84"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(debug = False):\n",
        "    num_rows = 10000 if debug else None\n",
        "    df = application_train_test(num_rows)\n",
        "    with timer(\"Process bureau and bureau_balance\"):\n",
        "        bureau = bureau_and_balance(num_rows)\n",
        "        print(\"Bureau df shape:\", bureau.shape)\n",
        "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
        "        del bureau\n",
        "        gc.collect()\n",
        "    with timer(\"Process previous_applications\"):\n",
        "        prev = previous_applications(num_rows)\n",
        "        print(\"Previous applications df shape:\", prev.shape)\n",
        "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
        "        del prev\n",
        "        gc.collect()\n",
        "    with timer(\"Process POS-CASH balance\"):\n",
        "        pos = pos_cash(num_rows)\n",
        "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
        "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
        "        del pos\n",
        "        gc.collect()\n",
        "    with timer(\"Process installments payments\"):\n",
        "        ins = installments_payments(num_rows)\n",
        "        print(\"Installments payments df shape:\", ins.shape)\n",
        "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
        "        del ins\n",
        "        gc.collect()\n",
        "    with timer(\"Process credit card balance\"):\n",
        "        cc = credit_card_balance(num_rows)\n",
        "        print(\"Credit card balance df shape:\", cc.shape)\n",
        "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
        "        del cc\n",
        "        gc.collect()\n",
        "#        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
        "    with timer(\"Run LightGBM with kfold\"):\n",
        "        feat_importance = kfold_lightgbm(df, num_folds= 10, stratified= False, debug= debug)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    submission_file_name = \"submission_kernel02.csv\"\n",
        "    with timer(\"Preprocess\"):\n",
        "        main()"
      ],
      "metadata": {
        "id": "XYO3LvdXPn5A",
        "outputId": "4208ab81-ce33-4c8d-eff6-9d6b2a8535da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 307511, test samples: 48744\n",
            "Bureau df shape: (305811, 116)\n",
            "Process bureau and bureau_balance - done in 27s\n",
            "Previous applications df shape: (338857, 249)\n",
            "Process previous_applications - done in 34s\n",
            "Pos-cash balance df shape: (337252, 18)\n",
            "Process POS-CASH balance - done in 21s\n",
            "Installments payments df shape: (339587, 26)\n",
            "Process installments payments - done in 42s\n",
            "Credit card balance df shape: (103558, 141)\n",
            "Process credit card balance - done in 31s\n",
            "Starting LightGBM. Train shape: (307507, 797), test shape: (48744, 797)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: CC_NAME_CONTRACT_STATUS_Active_MIN: object, CC_NAME_CONTRACT_STATUS_Active_MAX: object, CC_NAME_CONTRACT_STATUS_Approved_MIN: object, CC_NAME_CONTRACT_STATUS_Approved_MAX: object, CC_NAME_CONTRACT_STATUS_Completed_MIN: object, CC_NAME_CONTRACT_STATUS_Completed_MAX: object, CC_NAME_CONTRACT_STATUS_Demand_MIN: object, CC_NAME_CONTRACT_STATUS_Demand_MAX: object, CC_NAME_CONTRACT_STATUS_Refused_MIN: object, CC_NAME_CONTRACT_STATUS_Refused_MAX: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MIN: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MAX: object, CC_NAME_CONTRACT_STATUS_Signed_MIN: object, CC_NAME_CONTRACT_STATUS_Signed_MAX: object, CC_NAME_CONTRACT_STATUS_nan_MIN: object, CC_NAME_CONTRACT_STATUS_nan_MAX: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b75a63b76f96>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msubmission_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"submission_kernel02.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocess\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-b75a63b76f96>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(debug)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Run LightGBM with kfold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mfeat_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-779e167adb6a>\u001b[0m in \u001b[0;36mkfold_lightgbm\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     38\u001b[0m             )\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#                verbose= 200,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1285\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m             \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    956\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3635\u001b[0m                 )\n\u001b[1;32m   3636\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3637\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3638\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3639\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2574\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m                 \u001b[0;31m# create train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m                 self._lazy_init(\n\u001b[0m\u001b[1;32m   2577\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m                     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m             data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n\u001b[0m\u001b[1;32m   2107\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     return (\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0m_pandas_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_pandas_to_numpy\u001b[0;34m(data, target_dtype)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"np.typing.DTypeLike\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m ) -> np.ndarray:\n\u001b[0;32m--> 794\u001b[0;31m     \u001b[0m_check_for_bad_pandas_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;31m# most common case (no nullable dtypes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[0;34m(pandas_dtypes_series)\u001b[0m\n\u001b[1;32m    782\u001b[0m     ]\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbad_pandas_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;34m'pandas dtypes must be int, float or bool.\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;34mf'Fields with bad pandas dtypes: {\", \".join(bad_pandas_dtypes)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: CC_NAME_CONTRACT_STATUS_Active_MIN: object, CC_NAME_CONTRACT_STATUS_Active_MAX: object, CC_NAME_CONTRACT_STATUS_Approved_MIN: object, CC_NAME_CONTRACT_STATUS_Approved_MAX: object, CC_NAME_CONTRACT_STATUS_Completed_MIN: object, CC_NAME_CONTRACT_STATUS_Completed_MAX: object, CC_NAME_CONTRACT_STATUS_Demand_MIN: object, CC_NAME_CONTRACT_STATUS_Demand_MAX: object, CC_NAME_CONTRACT_STATUS_Refused_MIN: object, CC_NAME_CONTRACT_STATUS_Refused_MAX: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MIN: object, CC_NAME_CONTRACT_STATUS_Sent proposal_MAX: object, CC_NAME_CONTRACT_STATUS_Signed_MIN: object, CC_NAME_CONTRACT_STATUS_Signed_MAX: object, CC_NAME_CONTRACT_STATUS_nan_MIN: object, CC_NAME_CONTRACT_STATUS_nan_MAX: object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 10000\n",
        "cc = credit_card_balance(num_rows)"
      ],
      "metadata": {
        "id": "myPVR9L81waF",
        "outputId": "022631c4-920e-4394-a304-0f8073f3ba66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'CC_NAME_CONTRACT_STATUS_Sent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CC_NAME_CONTRACT_STATUS_Sent'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a3804fa20b6c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcredit_card_balance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-f97130b28ad4>\u001b[0m in \u001b[0;36mcredit_card_balance\u001b[0;34m(num_rows, nan_as_category)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mcc_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mcc_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CC_NAME_CONTRACT_STATUS_Sent'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cc['CC_NAME_CONTRACT_STATUS_Approved_MIN']"
      ],
      "metadata": {
        "id": "XowZzGIs2JgL",
        "outputId": "21c743c2-4c1d-4d42-a49b-ab2d3bd64490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'CC_NAME_CONTRACT_STATUS_Approved_MIN'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CC_NAME_CONTRACT_STATUS_Approved_MIN'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-05847c35d11b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CC_NAME_CONTRACT_STATUS_Approved_MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'CC_NAME_CONTRACT_STATUS_Approved_MIN'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n",
        "    # Divide in training/validation and test data\n",
        "    train_df = df[df['TARGET'].notnull()]\n",
        "    test_df = df[df['TARGET'].isnull()]\n",
        "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
        "    del df\n",
        "    gc.collect()\n",
        "    # Cross validation model\n",
        "    if stratified:\n",
        "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
        "    else:\n",
        "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n",
        "    # Create arrays and dataframes to store results\n",
        "    oof_preds = np.zeros(train_df.shape[0])\n",
        "    sub_preds = np.zeros(test_df.shape[0])\n",
        "    feature_importance_df = pd.DataFrame()\n",
        "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
        "\n",
        "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
        "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
        "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
        "\n",
        "        # LightGBM parameters found by Bayesian optimization\n",
        "        clf = LGBMClassifier(\n",
        "            nthread=4,\n",
        "            n_estimators=10000,\n",
        "            learning_rate=0.02,\n",
        "            num_leaves=34,\n",
        "            colsample_bytree=0.9497036,\n",
        "            subsample=0.8715623,\n",
        "            max_depth=8,\n",
        "            reg_alpha=0.041545473,\n",
        "            reg_lambda=0.0735294,\n",
        "            min_split_gain=0.0222415,\n",
        "            min_child_weight=39.3259775,\n",
        "            silent=-1,\n",
        "            verbose=-1,\n",
        "            )\n",
        "\n",
        "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
        "            eval_metric= 'auc',\n",
        "#                verbose= 200,\n",
        "#                early_stopping_rounds= 200\n",
        "                )\n",
        "\n",
        "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
        "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
        "\n",
        "        fold_importance_df = pd.DataFrame()\n",
        "        fold_importance_df[\"feature\"] = feats\n",
        "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
        "        fold_importance_df[\"fold\"] = n_fold + 1\n",
        "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
        "        del clf, train_x, train_y, valid_x, valid_y\n",
        "        gc.collect()\n",
        "\n",
        "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
        "    # Write submission file and plot feature importance\n",
        "    if not debug:\n",
        "        test_df['TARGET'] = sub_preds\n",
        "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
        "    display_importances(feature_importance_df)\n",
        "    return feature_importance_df"
      ],
      "metadata": {
        "id": "M7CGChiRQ-p8"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}